<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Offcial website of 'Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse Foreground-Conditioned Image Generation'">
  <meta name="keywords" content="Anywhere, Image inpainting, Multi-Agent">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Anywhere</title>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MRQC0YFE17');
</script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css" />
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <style>
    .container {
      max-width: 1280px;
      margin: 0 auto;
    }
  </style>


  <section class="hero">
    <div class="hero-body">
      <div class="container">
        
        <div class="container has-text-centered">
          
          <h1 class="title is-1 publication-title">
            Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse Foreground-Conditioned Image Generation
          </h1>

          <p class="is-size-3 has-text-weight-bold">🎉 <strong> Paper accepted at AAAI 2025! </strong> 🎉</p>
          
          <div class="is-size-2 publication-authors">
            <div class="author-block">
              <a href="mailto:sealical@outlook.com">Tianyidan Xie</a><sup>1</sup>,
            </div>
              Rui Ma<sup>2</sup>, Qian Wang<sup>*,3</sup><br>
              Xiaoqian Ye<sup>3</sup>, Feixuan Liu<sup>4</sup>, Lanjun Wang<sup>5</sup>,<br>
              Ying Tai<sup>1</sup>, Zhenyu Zhang<sup>1</sup>, and Zili Yi<sup>*,1</sup><br>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Nanjing University </span>
            <span class="author-block"><sup>2</sup>Jilin University </span>
            <span class="author-block"><sup>5</sup>Tianjin University </span>
            <br>
            <span class="author-block"><sup>3</sup>China Mobile Communications Group</span>
            <br>
             <span class="author-block"><sup>4</sup>Larkagent AI </span><br>
            <span class="author-block"><sup>*</sup>Corresponding Author</span> 
<!--             <br>
            <span class="author-block">sealical@outlook.com</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->

              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.18598" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/Sealical/anywhere-multi-agent"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <img src="./static/documents/teaser.png" alt="Teaser Image" width="60%">
      <h2 class="subtitle has-text-centered">
        Our approach enables any object to be placed in any suitable and diverse locations.
      </h2>
    </div>
  </div>
</section>



  <section class="section">
    <div class="container is-max-desktop">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>

          <div class="content has-text-justified">
            <p>
              Recent advancements in image-conditioned image generation have demonstrated substantial progress. However, foreground-conditioned image generation remains underexplored, encountering challenges such as compromised object integrity, foreground-background inconsistencies, limited diversity, and reduced control flexibility. These challenges arise from current end-to-end inpainting models, which suffer from inaccurate training masks, limited foreground semantic understanding, data distribution biases, and inherent interference between visual and textual prompts. To overcome these limitations, we present <strong>Anywhere</strong>, a multi-agent framework that departs from the traditional end-to-end approach. In this framework, each agent is specialized in a distinct aspect, such as foreground understanding, diversity enhancement, object integrity protection, and textual prompt consistency. Our framework is further enhanced with the ability to incorporate optional user textual inputs, perform automated quality assessments, and initiate re-generation as needed. Comprehensive experiments demonstrate that this modular design effectively overcomes the limitations of existing end-to-end models, resulting in higher fidelity, quality, diversity and controllability in foreground-conditioned image generation. Additionally, the Anywhere framework is extensible, allowing it to benefit from future advancements in each individual agent.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

  </section>

  <section class="method">
    <div class="container is-max-desktop">

      <!-- Method. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>

          <div class="content has-text-justified">
            <p>
              Anywhere is a multi-agent image generation framework comprising agents of various modalities, such as large language model, visual language model, controlled image generation model, and inpainting model. Its workflow encompasses three modules: the prompt generation module, the image generation module, and the quality evaluator, as illustrated in Figure Anywhere achieves background generation by processing images through modules utilizing diverse agents.
            </p>
          </div>

          <div class="container is-max-desktop">
            <img src="./static/documents/framework.png" alt="Image0" height="100%">
          </div>


        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>


<!--   <div class="section">
    <div class="container">
      <h2 class="title has-text-centered">Comparison with Previous Inpainting model</h3>
      <div id="results-carousel" class="carousel results-carousel carousel-control-prev carousel-inner" data-ride="carousel">
        <div>
          <div class="results-item">
            <img src="./static/documents/opensource_comparison.jpg", height="100">
          </div>
        </div>

      <div>
          <div class="results-item">
            <img src="./static/documents/opensource_comparison_appendix1.jpg" alt="Image0" height="90%">
          </div>
        </div>

        <div>
          <div class="results-item">
            <img src="./static/documents/opensource_comparison_appendix2.jpg" alt="Image0" weight="65%">
          </div>
        </div>


      </div>

  </div class="section"> -->

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Comparison with Previous Works</h2>

          <div class="container is-max-desktop">
            <img src="./static/documents/opensource_comparison.png" alt="Image0" height="100%">
          </div>

          <div class="content has-text-justified">
            <p>
              We compare our approach to advanced inpainting models on foreground-conditioned image generation tasks in both text-free (I2I) and text-guided (TI2I) scenarios. These results are generated using unconstrained, in-the-wild foreground images. Red color indicates missing elements in generated images. The inpainting models used for comparison include HD-Painter (<strong>HDP</strong>), BrushNet (<strong>BN</strong>), and Stable Diffusion 2.0 Inpainting (<strong>SDI</strong>).  
            </p>
          </div>

        <h2 class="title is-3">Comparison with Business Products</h2>
          <div class="container is-max-desktop">
            <img src="./static/documents/business_comparison.jpg" alt="Image0" height="100%">
          </div>

        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">The Influence of Different Modules in Our Anywhere Framework</h2>

          <div class="container is-max-desktop has-text-centered">
            <img src="./static/documents/ablation_prompt.png" alt="Image0" width="50%">
          </div>

          <div class="content has-text-justified">
            <p>
              The prompt generation module (PG). It reveals that without the prompt generation module, our system tends to produce less diverse results with uniform empty backgrounds.
            </p>
          </div>


          <div class="container is-max-desktop">
            <img src="./static/documents/ablation_repainter.png" alt="Image0" width="50%">
          </div>

          <div class="content has-text-centered">
            <p>
              The Template Repainter. As shown, the repainting agent contributes to mitigating the “over-imagination” issue.
            </p>
          </div>


          <div class="container is-max-desktop">
            <img src="./static/documents/ablation_image.png" alt="Image0" width="50%">
          </div>

          <div class="content has-text-justified">
            <p>
              The Image Enchancer. This agent enhances the overall quality of the composite image, focusing on fine details, color balance, and smooth transitions. 
            </p>
          </div>


          <div class="container is-max-desktop">
            <img src="./static/documents/ablation_quality.png" alt="Image0" width="60%">
          </div>

          <div class="content has-text-justified">
            <p>
              The Quality Evaluator. As shown, the mechanism of feedback-based regeneration significantly improves the quality of the final outcomes.
            </p>
          </div>

        </div>
      </div>
      <!--/ Abstract. -->
  </section>



  <section class="section">
    <div class="container is-max-desktop">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">More Comparisons</h2>

          <div class="container is-max-desktop">
            <img src="./static/documents/more_img2img.png" alt="Image0" width="80%">
          </div>
          <div class="content has-text-justified">
            <p>
              More qualitative results on text-free scenarios (I2I).
            </p>
          </div>


          <div class="container is-max-desktop">
            <img src="./static/documents/more_ti2i.png" alt="Image0" width="80%">
          </div>
          <div class="content has-text-justified">
            <p>
              More qualitative results on text-guided scenarios (TI2I).
            </p>
          </div>


        </div>
      </div>
      <!--/ Abstract. -->

  </section>

  <section class="section" id="BibTeX">
    <div class="container content is-max-desktop">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{xie2024anywhere,
  title={Anywhere: A Multi-Agent Framework for Reliable and Diverse Foreground-Conditioned Image Inpainting},
  author={Xie, Tianyidan and Ma, Rui and Wang, Qian and Ye, Xiaoqian and Liu, Feixuan and Tai, Ying and Zhang, Zhenyu and Yi, Zili},
  journal={arXiv preprint arXiv:2404.18598},
  year={2024}
}</code></pre>
  </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          The website template is borrowed from HyperNeRF.
        </p>
      </div>
    </div>
  </footer>

  <script type="text/javascript" src="./static/slick/slick.js"></script>
</body>

</html>
